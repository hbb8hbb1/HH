#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç°æœ‰æ•°æ®è¿ç§»è„šæœ¬ - è§„åˆ™æ˜ å°„é˜¶æ®µ
ä»ç°æœ‰å­—æ®µï¼ˆtitle, company, role, tags, processedContentï¼‰æ¨æ–­ tagDimensions
"""

import os
import re
from pymongo import MongoClient
from typing import Dict, Any, List, Tuple

# MongoDB è¿æ¥
MONGO_URI = os.environ.get("MONGO_URI", "mongodb://localhost:27017/offermagnet")

# æŠ€æœ¯æ ˆå…³é”®è¯æ˜ å°„ï¼ˆä» tags ä¸­è¯†åˆ«ï¼‰
TECH_KEYWORDS = {
    # å‰ç«¯
    "React", "Vue", "Angular", "TypeScript", "JavaScript", "JS", "HTML", "CSS", "SASS", "SCSS",
    "Webpack", "Vite", "Next.js", "Nuxt", "Svelte",
    # åç«¯
    "Node.js", "Python", "Java", "Go", "Golang", "C++", "C#", "PHP", "Ruby", "Rust",
    "Spring", "Django", "Flask", "Express", "FastAPI", "Laravel", "Rails",
    # æ•°æ®åº“
    "MySQL", "PostgreSQL", "MongoDB", "Redis", "Elasticsearch", "Cassandra",
    # ç®—æ³•/ML
    "PyTorch", "TensorFlow", "Keras", "Scikit-learn", "Pandas", "NumPy",
    "Machine Learning", "ML", "Deep Learning", "NLP", "CV", "Computer Vision",
    # å…¶ä»–
    "Docker", "Kubernetes", "AWS", "GCP", "Azure", "Git", "Linux"
}

# åœ°ç‚¹å…³é”®è¯
LOCATION_KEYWORDS = {
    "åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³", "æ­å·", "å¹¿å·", "æˆéƒ½", "å—äº¬", "æ­¦æ±‰", "è¥¿å®‰", "è‹å·",
    "ç¡…è°·", "San Francisco", "SF", "Seattle", "New York", "NYC", "London", "ä¼¦æ•¦",
    "æ–°åŠ å¡", "Singapore", "é¦™æ¸¯", "Hong Kong", "Tokyo", "ä¸œäº¬"
}

# æ‹›è˜ç±»å‹å…³é”®è¯
RECRUIT_TYPE_KEYWORDS = {
    "æ ¡æ‹›": ["æ ¡æ‹›", "æ ¡å›­æ‹›è˜", "åº”å±Š", "åº”å±Šç”Ÿ", "new grad", "newgrad"],
    "ç¤¾æ‹›": ["ç¤¾æ‹›", "ç¤¾ä¼šæ‹›è˜", "experienced", "senior"],
    "æš‘æœŸå®ä¹ ": ["æš‘æœŸå®ä¹ ", "summer intern", "summer internship"],
    "æ—¥å¸¸å®ä¹ ": ["æ—¥å¸¸å®ä¹ ", "å®ä¹ ", "intern", "internship"]
}

# Role åˆ° Category çš„æ˜ å°„è§„åˆ™
ROLE_TO_CATEGORY = {
    # ç ”å‘ç›¸å…³
    "software engineer": "ç ”å‘",
    "software engineering": "ç ”å‘",
    "engineer": "ç ”å‘",
    "developer": "ç ”å‘",
    "å¼€å‘": "ç ”å‘",
    "ç ”å‘": "ç ”å‘",
    "å‰ç«¯": "ç ”å‘",
    "åç«¯": "ç ”å‘",
    "full stack": "ç ”å‘",
    "å…¨æ ˆ": "ç ”å‘",
    # ç®—æ³•ç›¸å…³
    "data scientist": "ç®—æ³•",
    "data science": "ç®—æ³•",
    "data scientist": "ç®—æ³•",
    "machine learning": "ç®—æ³•",
    "ml engineer": "ç®—æ³•",
    "algorithm": "ç®—æ³•",
    "ç®—æ³•": "ç®—æ³•",
    "ç®—æ³•å·¥ç¨‹å¸ˆ": "ç®—æ³•",
    # äº§å“ç›¸å…³
    "product manager": "äº§å“",
    "pm": "äº§å“",
    "äº§å“": "äº§å“",
    "äº§å“ç»ç†": "äº§å“"
}

# Role åˆ° SubRole çš„æ˜ å°„è§„åˆ™
ROLE_TO_SUBROLE = {
    # å‰ç«¯
    "frontend": "å‰ç«¯",
    "front-end": "å‰ç«¯",
    "å‰ç«¯": "å‰ç«¯",
    "å‰ç«¯å·¥ç¨‹å¸ˆ": "å‰ç«¯",
    "web developer": "å‰ç«¯",
    # åç«¯
    "backend": "åç«¯",
    "back-end": "åç«¯",
    "åç«¯": "åç«¯",
    "åç«¯å·¥ç¨‹å¸ˆ": "åç«¯",
    "server": "åç«¯",
    # ç§»åŠ¨ç«¯
    "mobile": "ç§»åŠ¨ç«¯",
    "ios": "ç§»åŠ¨ç«¯",
    "android": "ç§»åŠ¨ç«¯",
    "ç§»åŠ¨ç«¯": "ç§»åŠ¨ç«¯",
    # ç®—æ³•
    "machine learning": "æœºå™¨å­¦ä¹ ",
    "ml": "æœºå™¨å­¦ä¹ ",
    "cv": "CV",
    "computer vision": "CV",
    "nlp": "NLP",
    "natural language processing": "NLP",
    "recommendation": "æ¨èç³»ç»Ÿ",
    "recommendation system": "æ¨èç³»ç»Ÿ",
    "llm": "å¤§æ¨¡å‹/LLM",
    "large language model": "å¤§æ¨¡å‹/LLM"
}


def extract_technologies(tags: List[str], title: str, content: str) -> List[str]:
    """ä» tagsã€titleã€content ä¸­æå–æŠ€æœ¯æ ˆ"""
    found_techs = set()
    all_text = " ".join(tags) + " " + title + " " + (content or "")[:500]
    
    for tech in TECH_KEYWORDS:
        # æ£€æŸ¥ tags ä¸­æ˜¯å¦åŒ…å«
        for tag in tags:
            if tech.lower() in tag.lower() or tag.lower() in tech.lower():
                found_techs.add(tech)
        # æ£€æŸ¥ title å’Œ content
        if tech.lower() in all_text.lower():
            found_techs.add(tech)
    
    return sorted(list(found_techs))


def extract_location(tags: List[str], title: str) -> str:
    """ä» tags å’Œ title ä¸­æå–åœ°ç‚¹"""
    all_text = " ".join(tags) + " " + title
    
    for location in LOCATION_KEYWORDS:
        if location in all_text:
            return location
    
    return ""


def extract_recruit_type(tags: List[str], title: str) -> str:
    """ä» tags å’Œ title ä¸­æå–æ‹›è˜ç±»å‹"""
    all_text = " ".join(tags) + " " + title
    
    for recruit_type, keywords in RECRUIT_TYPE_KEYWORDS.items():
        for keyword in keywords:
            if keyword.lower() in all_text.lower():
                return recruit_type
    
    return "å…¶ä»–"


def infer_category(role: str) -> str:
    """ä» role æ¨æ–­ category"""
    role_lower = role.lower()
    
    for keyword, category in ROLE_TO_CATEGORY.items():
        if keyword.lower() in role_lower:
            return category
    
    return ""


def infer_sub_role(role: str, tags: List[str]) -> str:
    """ä» role å’Œ tags æ¨æ–­ subRole"""
    role_lower = role.lower()
    all_text = " ".join(tags).lower()
    
    # å…ˆæ£€æŸ¥ role
    for keyword, sub_role in ROLE_TO_SUBROLE.items():
        if keyword.lower() in role_lower:
            return sub_role
    
    # å†æ£€æŸ¥ tags
    for keyword, sub_role in ROLE_TO_SUBROLE.items():
        if keyword.lower() in all_text:
            return sub_role
    
    return ""


def extract_custom_tags(tags: List[str], technologies: List[str]) -> List[str]:
    """æå–è‡ªå®šä¹‰æ ‡ç­¾ï¼ˆæ’é™¤æŠ€æœ¯æ ˆå’Œç»´åº¦æ ‡ç­¾ï¼‰"""
    custom = []
    dimension_keywords = set()
    
    # æ”¶é›†æ‰€æœ‰ç»´åº¦å…³é”®è¯
    for keywords in [LOCATION_KEYWORDS, RECRUIT_TYPE_KEYWORDS]:
        for kw in keywords:
            dimension_keywords.add(kw.lower())
    
    for tag in tags:
        tag_lower = tag.lower()
        # æ’é™¤æŠ€æœ¯æ ˆ
        is_tech = any(tech.lower() in tag_lower or tag_lower in tech.lower() for tech in technologies)
        # æ’é™¤ç»´åº¦å…³é”®è¯
        is_dimension = tag_lower in dimension_keywords
        # æ’é™¤å…¬å¸åç§°ï¼ˆé€šå¸¸å·²ç»åœ¨ company å­—æ®µä¸­ï¼‰
        # æ’é™¤æ‹›è˜ç±»å‹å…³é”®è¯
        is_recruit = any(kw in tag_lower for keywords in RECRUIT_TYPE_KEYWORDS.values() for kw in keywords)
        
        if not (is_tech or is_dimension or is_recruit):
            custom.append(tag)
    
    return custom[:5]  # é™åˆ¶æœ€å¤š5ä¸ªè‡ªå®šä¹‰æ ‡ç­¾


def infer_tag_dimensions(post: Dict[str, Any]) -> Dict[str, Any]:
    """ä»ç°æœ‰å­—æ®µæ¨æ–­ tagDimensions"""
    tags = post.get("tags", [])
    title = post.get("title", "")
    role = post.get("role", "")
    company = post.get("company", "")
    processed_content = post.get("processedContent", "") or post.get("originalContent", "")
    
    # æå–å„ä¸ªç»´åº¦
    technologies = extract_technologies(tags, title, processed_content)
    location = extract_location(tags, title)
    recruit_type = extract_recruit_type(tags, title)
    category = infer_category(role)
    sub_role = infer_sub_role(role, tags)
    custom = extract_custom_tags(tags, technologies)
    
    return {
        "technologies": technologies,
        "recruitType": recruit_type,
        "location": location,
        "category": category,
        "subRole": sub_role,
        "custom": custom
    }


def migrate_posts(collection, dry_run: bool = False) -> Tuple[int, int, int]:
    """è¿ç§»æ‰€æœ‰å¸–å­"""
    # æŸ¥æ‰¾æ²¡æœ‰ tagDimensions æˆ– tagDimensions ä¸ºç©ºçš„æ•°æ®
    query = {
        "$or": [
            {"tagDimensions": {"$exists": False}},
            {"tagDimensions": None},
            {"tagDimensions.technologies": {"$exists": False}},
            {"tagDimensions.technologies": []}
        ]
    }
    
    posts = list(collection.find(query))
    total = len(posts)
    print(f"\nğŸ“Š æ‰¾åˆ° {total} æ¡éœ€è¦è¿ç§»çš„æ•°æ®")
    
    if total == 0:
        print("âœ… æ‰€æœ‰æ•°æ®å·²è¿ç§»å®Œæˆ")
        return 0, 0, 0
    
    updated = 0
    skipped = 0
    failed = 0
    
    for i, post in enumerate(posts, 1):
        try:
            # æ¨æ–­ tagDimensions
            tag_dimensions = infer_tag_dimensions(post)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
            has_data = (
                tag_dimensions["technologies"] or
                tag_dimensions["location"] or
                tag_dimensions["recruitType"] != "å…¶ä»–" or
                tag_dimensions["category"] or
                tag_dimensions["subRole"] or
                tag_dimensions["custom"]
            )
            
            if not has_data:
                skipped += 1
                if i % 50 == 0:
                    print(f"   [{i}/{total}] â­ï¸  è·³è¿‡ï¼ˆæ— æ³•æ¨æ–­ï¼‰")
                continue
            
            if dry_run:
                print(f"   [{i}/{total}] ğŸ“ å°†æ›´æ–°: {post.get('title', '')[:50]}")
                print(f"      tagDimensions: {tag_dimensions}")
            else:
                # æ›´æ–°æ•°æ®åº“
                collection.update_one(
                    {"_id": post["_id"]},
                    {"$set": {"tagDimensions": tag_dimensions}}
                )
                updated += 1
            
            if i % 50 == 0:
                print(f"   [{i}/{total}] âœ… å·²å¤„ç† (æ›´æ–°: {updated}, è·³è¿‡: {skipped}, å¤±è´¥: {failed})")
        
        except Exception as e:
            failed += 1
            print(f"   [{i}/{total}] âŒ å¤„ç†å¤±è´¥: {e}")
            if failed <= 5:
                print(f"      é”™è¯¯è¯¦æƒ…: {post.get('title', '')[:50]}")
    
    return updated, skipped, failed


def main():
    import argparse
    parser = argparse.ArgumentParser(description="è¿ç§»ç°æœ‰æ•°æ®åˆ° tagDimensionsï¼ˆè§„åˆ™æ˜ å°„ï¼‰")
    parser.add_argument("--dry-run", action="store_true", help="ä»…é¢„è§ˆï¼Œä¸å®é™…æ›´æ–°æ•°æ®åº“")
    parser.add_argument("--mongo-uri", default=MONGO_URI, help="MongoDB è¿æ¥å­—ç¬¦ä¸²")
    args = parser.parse_args()
    
    print("ğŸ”— è¿æ¥ MongoDB...")
    try:
        client = MongoClient(args.mongo_uri, serverSelectionTimeoutMS=5000)
        client.server_info()  # æµ‹è¯•è¿æ¥
        db = client.get_database()
        collection = db.posts
        print("âœ… MongoDB è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ MongoDB è¿æ¥å¤±è´¥: {e}")
        return
    
    if args.dry_run:
        print("\nğŸ” é¢„è§ˆæ¨¡å¼ï¼ˆä¸ä¼šå®é™…æ›´æ–°æ•°æ®åº“ï¼‰")
    
    print("\nğŸš€ å¼€å§‹è§„åˆ™æ˜ å°„è¿ç§»...")
    updated, skipped, failed = migrate_posts(collection, dry_run=args.dry_run)
    
    print(f"\nğŸ“Š è¿ç§»å®Œæˆ:")
    print(f"   âœ… æ›´æ–°: {updated} æ¡")
    print(f"   â­ï¸  è·³è¿‡: {skipped} æ¡ï¼ˆæ— æ³•æ¨æ–­ï¼‰")
    print(f"   âŒ å¤±è´¥: {failed} æ¡")
    
    if args.dry_run:
        print("\nğŸ’¡ ä½¿ç”¨ --dry-run=false æˆ–ç§»é™¤ --dry-run å‚æ•°æ¥å®é™…æ‰§è¡Œæ›´æ–°")
    else:
        # ç»Ÿè®¡è¿ç§»åçš„æ•°æ®
        total_with_dims = collection.count_documents({"tagDimensions": {"$exists": True}})
        total_posts = collection.count_documents({})
        print(f"\nğŸ“ˆ æ•°æ®åº“ç»Ÿè®¡:")
        print(f"   æ€»å¸–å­æ•°: {total_posts}")
        print(f"   æœ‰ tagDimensions: {total_with_dims}")
        print(f"   è¦†ç›–ç‡: {total_with_dims/total_posts*100:.1f}%" if total_posts > 0 else "   è¦†ç›–ç‡: 0%")


if __name__ == "__main__":
    main()

