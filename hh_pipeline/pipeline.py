#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HH Pipeline - ç»Ÿä¸€çš„HTMLé¢ç»å¤„ç†æµç¨‹

åŠŸèƒ½ï¼š
1. è§£æHTMLæ–‡ä»¶ä¸ºraw JSON
2. é€šè¿‡AIæ¸…æ´—ä¸ºfinal JSONï¼ˆå¿…é¡»æœ‰AI APIï¼‰
3. å¯é€‰ï¼šå¯¼å…¥åˆ°åç«¯æ•°æ®åº“
4. å¹‚ç­‰å»é‡ï¼šåŸºäºå†…å®¹hashï¼Œå·²å¤„ç†çš„æ–‡ä»¶è‡ªåŠ¨è·³è¿‡

ä½¿ç”¨æ–¹æ³•ï¼š
    python pipeline.py run --html-dir ./input_html --out-dir ./out
    python pipeline.py run --html-dir ./input_html --out-dir ./out --api-base http://localhost:5001 --email user@example.com --password pass
"""

import argparse
import hashlib
import json
import os
import re
import sqlite3
import sys
import time
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

import requests
from bs4 import BeautifulSoup

# ==================== é…ç½® ====================

# AI APIé…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨QWENï¼Œå¦‚æœæœªé…ç½®åˆ™å°è¯•GEMINIï¼‰
QWEN_API_KEY = os.environ.get("QWEN_API_KEY")
GEMINI_API_KEY = os.environ.get("API_KEY") or os.environ.get("GEMINI_API_KEY")
AI_API_KEY = QWEN_API_KEY or GEMINI_API_KEY
AI_TYPE = "qwen" if QWEN_API_KEY else ("gemini" if GEMINI_API_KEY else None)

QWEN_API_URL = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
GEMINI_MODEL = "gemini-1.5-flash"

CONCURRENCY = int(os.environ.get("CONCURRENCY", "10"))  # é»˜è®¤å¹¶å‘æ•°ä»3å¢åŠ åˆ°10
MAX_RETRIES = int(os.environ.get("MAX_RETRIES", "3"))
API_TIMEOUT = int(os.environ.get("API_TIMEOUT", "30"))  # AI APIè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

# ==================== AIå¤„ç† ====================

def check_ai_api() -> Tuple[bool, str]:
    """æ£€æŸ¥AI APIæ˜¯å¦å¯ç”¨ï¼ˆå¼ºåˆ¶è¦æ±‚ï¼‰"""
    if not AI_API_KEY:
        return False, "æœªé…ç½®AI API Keyã€‚è¯·è®¾ç½® QWEN_API_KEY æˆ– API_KEY (Gemini) ç¯å¢ƒå˜é‡"
    
    # æµ‹è¯•APIå¯ç”¨æ€§
    try:
        if AI_TYPE == "qwen":
            response = requests.post(
                QWEN_API_URL,
                headers={'Authorization': f'Bearer {AI_API_KEY}'},
                json={'model': 'qwen-plus', 'input': {'messages': [{'role': 'user', 'content': 'test'}]}},
                timeout=5
            )
            if response.status_code == 401:
                return False, f"QWEN_API_KEY æ— æ•ˆï¼ˆ401é”™è¯¯ï¼‰"
            return True, "Qwen APIå¯ç”¨"
        else:  # gemini
            # ç®€å•æ£€æŸ¥keyæ ¼å¼
            if len(AI_API_KEY) < 10:
                return False, "API_KEY æ ¼å¼å¯èƒ½æ— æ•ˆ"
            return True, "Gemini APIå·²é…ç½®"
    except Exception as e:
        return False, f"AI APIæ£€æŸ¥å¤±è´¥: {e}"
    
    return True, "AI APIå¯ç”¨"

def build_prompt(title: str, content_text: str) -> str:
    """æ„å»ºAIæ¸…æ´—æç¤ºè¯"""
    return f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„äº’è”ç½‘æ±‚èŒé¢ç»ä¸»ç¼–ã€‚
è¯·å°†ç”¨æˆ·æä¾›çš„åŸå§‹é¢ç»å†…å®¹æ¸…æ´—ã€åŒ¿ååŒ–å¹¶é‡ç»„ä¸º"äº§å“çº§å¯è¯»"çš„ç»“æ„åŒ–é¢ç»ã€‚

ç¡¬æ€§è¦æ±‚ï¼š
1) è¾“å‡ºè¯­è¨€ï¼šå¿…é¡»ä½¿ç”¨ã€ç®€ä½“ä¸­æ–‡ã€‘ã€‚
2) åŒ¿ååŒ–ï¼šç§»é™¤é¢è¯•å®˜å§“åã€å…·ä½“æ—¥æœŸã€æ¥¼ä¸»IDã€å­¦æ ¡/é‚®ç®±/ç”µè¯ç­‰éšç§ã€‚
3) ç»“æ„ï¼šä½¿ç”¨ Markdownï¼Œå¹¶å°½é‡æŒ‰ä»¥ä¸‹éª¨æ¶ç»„ç»‡ï¼ˆå¯æŒ‰å†…å®¹å¢åˆ å°èŠ‚ï¼Œä½†ä¿æŒå±‚çº§æ¸…æ™°ï¼‰ï¼š
   - ## åŸºæœ¬ä¿¡æ¯ï¼ˆå…¬å¸/å²—ä½/ç»“æœ/éš¾åº¦ï¼‰
   - ## æ—¶é—´çº¿ï¼ˆå¦‚æœèƒ½ä»å†…å®¹æ¨æ–­ï¼‰
   - ## é¢è¯•è¿‡ç¨‹ï¼ˆæŒ‰è½®æ¬¡ï¼šç¬”è¯•/OA/ä¸€é¢/äºŒé¢/HRç­‰ï¼‰
   - ## é¢˜ç›®æ€»ç»“ï¼ˆæŠŠé¢˜ç›®åˆ—è¡¨åŒ–ï¼‰
   - ## ä¸ªäººæ€»ç»“ï¼ˆç»éªŒä¸å»ºè®®ï¼‰
4) åªåŸºäºåŸæ–‡ï¼Œä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„è½®æ¬¡æˆ–ç»†èŠ‚ï¼›ä¸ç¡®å®šå°±å†™"æœªæåŠ/ä¸æ˜ç¡®"ã€‚
5) è¾“å‡ºä¸º JSON æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
   - title: ç²¾ç‚¼ã€ä¸“ä¸šçš„ä¸­æ–‡æ ‡é¢˜
   - processedContent: Markdown æ ¼å¼çš„ç»“æ„åŒ–é¢ç»æ­£æ–‡
   - company: å…¬å¸åç§°ï¼ˆå¤–ä¼ç”¨è‹±æ–‡ï¼Œå¦‚"Meta"ã€"Google"ï¼‰
   - role: å²—ä½ï¼ˆä¸­æ–‡æˆ–è‹±æ–‡å‡å¯ï¼Œå¦‚"è½¯ä»¶å·¥ç¨‹å¸ˆ"ã€"Software Engineer"ï¼‰
   - difficulty: éš¾åº¦ 1-5ï¼ˆæ•´æ•°ï¼‰
   - tags: 3-8 ä¸ªæ ‡ç­¾çš„æ•°ç»„ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰
   - tagDimensions: ç»“æ„åŒ–æ ‡ç­¾å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
     * technologies: æŠ€æœ¯æ ˆæ•°ç»„ï¼Œå¦‚ ["React", "TypeScript", "Node.js"]ï¼ˆä»å†…å®¹ä¸­æå–æåˆ°çš„æŠ€æœ¯ï¼‰
     * recruitType: æ‹›è˜ç±»å‹ï¼Œå¯é€‰å€¼ï¼š"æ ¡æ‹›"ã€"ç¤¾æ‹›"ã€"æš‘æœŸå®ä¹ "ã€"æ—¥å¸¸å®ä¹ "ã€"å…¶ä»–"ï¼ˆä»æ ‡é¢˜æˆ–å†…å®¹è¯†åˆ«ï¼‰
     * location: åœ°ç‚¹å­—ç¬¦ä¸²ï¼Œå¦‚ "åŒ—äº¬"ã€"ä¸Šæµ·"ã€"æ·±åœ³"ã€"ç¡…è°·"ï¼ˆä»æ ‡é¢˜æˆ–å†…å®¹æå–ï¼Œä¸ç¡®å®šåˆ™ç©ºå­—ç¬¦ä¸²ï¼‰
     * category: éƒ¨é—¨ç±»åˆ«ï¼Œå¯é€‰å€¼ï¼š"ç ”å‘"ã€"ç®—æ³•"ã€"äº§å“"ã€"è®¾è®¡"ã€"è¿è¥"ã€"å¸‚åœº"ã€"HR"ï¼ˆæ ¹æ®roleå’Œå†…å®¹åˆ¤æ–­ï¼‰
     * subRole: å­è§’è‰²å­—ç¬¦ä¸²ï¼Œå¦‚ "å‰ç«¯"ã€"åç«¯"ã€"æœºå™¨å­¦ä¹ "ã€"CV"ï¼ˆæ ¹æ®roleå’Œå†…å®¹åˆ¤æ–­ï¼‰
     * custom: è‡ªå®šä¹‰æ ‡ç­¾æ•°ç»„ï¼Œå¦‚ ["æ‰‹å†™ä»£ç ", "ç³»ç»Ÿè®¾è®¡", "ç®—æ³•é¢˜"]ï¼ˆå…¶ä»–æœ‰ä»·å€¼çš„æ ‡ç­¾ï¼‰

åŸå§‹æ ‡é¢˜ï¼ˆå¯èƒ½å¾ˆç³™ï¼‰ï¼š
{title}

åŸå§‹æ­£æ–‡ï¼ˆå·²å»æ‰HTMLæ ‡ç­¾ï¼Œä»…ä¿ç•™æ–‡æœ¬ï¼‰ï¼š
{content_text}

è¯·è¿”å› JSON æ ¼å¼ï¼ŒåŒ…å« title, processedContent, company, role, difficulty, tags, tagDimensions å­—æ®µã€‚
tagDimensions å¿…é¡»åŒ…å«æ‰€æœ‰å­å­—æ®µï¼ˆtechnologies, recruitType, location, category, subRole, customï¼‰ã€‚
åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""

def call_qwen_api(prompt: str, retries: int = MAX_RETRIES) -> Dict[str, Any]:
    """è°ƒç”¨Qwen API"""
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {QWEN_API_KEY}'
    }
    
    data = {
        'model': 'qwen-plus',
        'input': {
            'messages': [{'role': 'user', 'content': prompt}]
        },
        'parameters': {'result_format': 'message'}
    }
    
    for attempt in range(retries + 1):
        try:
            response = requests.post(QWEN_API_URL, headers=headers, json=data, timeout=API_TIMEOUT)
            
            if response.status_code == 200:
                result = response.json()
                text = result['output']['choices'][0]['message']['content']
                if not text:
                    raise ValueError("Empty model response text")
                
                # æå–JSON
                text = text.strip()
                if text.startswith("```json"):
                    text = text[7:]
                if text.startswith("```"):
                    text = text[3:]
                if text.endswith("```"):
                    text = text[:-3]
                text = text.strip()
                
                return json.loads(text)
            elif response.status_code == 429:
                if attempt < retries:
                    time.sleep(min(2 * (attempt + 1), 12))
                    continue
                raise Exception(f"Rate limited after {retries} retries")
            else:
                raise Exception(f"API returned {response.status_code}: {response.text[:200]}")
        except json.JSONDecodeError as e:
            raise ValueError(f"Failed to parse JSON: {e}")
        except Exception as e:
            if attempt < retries and any(k in str(e).lower() for k in ['429', 'rate', 'timeout']):
                time.sleep(min(2 * (attempt + 1), 12))
                continue
            raise
    
    raise Exception("Max retries exceeded")

def call_gemini_api(prompt: str, retries: int = MAX_RETRIES) -> Dict[str, Any]:
    """è°ƒç”¨Gemini APIï¼ˆéœ€è¦google-generativeaiåº“ï¼‰"""
    try:
        import google.generativeai as genai
    except ImportError:
        raise ImportError("éœ€è¦å®‰è£… google-generativeai: pip install google-generativeai")
    
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel(GEMINI_MODEL)
    
    for attempt in range(retries + 1):
        try:
            response = model.generate_content(
                prompt,
                generation_config={
                    "response_mime_type": "application/json",
                }
            )
            text = response.text.strip()
            if text.startswith("```json"):
                text = text[7:]
            if text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            return json.loads(text.strip())
        except Exception as e:
            if attempt < retries and any(k in str(e).lower() for k in ['429', 'rate', 'timeout']):
                time.sleep(min(2 * (attempt + 1), 12))
                continue
            raise
    
    raise Exception("Max retries exceeded")

def process_with_ai(raw_data: Dict[str, Any]) -> Dict[str, Any]:
    """ä½¿ç”¨AIæ¸…æ´—rawæ•°æ®ä¸ºfinalæ ¼å¼"""
    prompt = build_prompt(raw_data.get("title", ""), raw_data.get("originalContentText", ""))
    
    if AI_TYPE == "qwen":
        processed = call_qwen_api(prompt)
    elif AI_TYPE == "gemini":
        processed = call_gemini_api(prompt)
    else:
        raise RuntimeError("AI APIæœªé…ç½®")
    
    # éªŒè¯å¿…éœ€å­—æ®µ
    required_fields = ["title", "processedContent", "company", "role", "difficulty", "tags", "tagDimensions"]
    missing = [f for f in required_fields if f not in processed]
    if missing:
        raise ValueError(f"AIè¿”å›ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing}")
    
    # éªŒè¯ tagDimensions ç»“æ„
    tag_dims = processed.get("tagDimensions", {})
    required_dims = ["technologies", "recruitType", "location", "category", "subRole", "custom"]
    missing_dims = [d for d in required_dims if d not in tag_dims]
    if missing_dims:
        raise ValueError(f"tagDimensions ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_dims}")
    
    # éªŒè¯å’Œè§„èŒƒåŒ– tagDimensions
    tag_dimensions = {
        "technologies": list(tag_dims.get("technologies", [])) if isinstance(tag_dims.get("technologies"), list) else [],
        "recruitType": str(tag_dims.get("recruitType", "å…¶ä»–")).strip() or "å…¶ä»–",
        "location": str(tag_dims.get("location", "")).strip(),
        "category": str(tag_dims.get("category", "")).strip() or "",
        "subRole": str(tag_dims.get("subRole", "")).strip() or "",
        "custom": list(tag_dims.get("custom", [])) if isinstance(tag_dims.get("custom"), list) else []
    }
    
    # éªŒè¯ recruitType å€¼
    valid_recruit_types = ["æ ¡æ‹›", "ç¤¾æ‹›", "æš‘æœŸå®ä¹ ", "æ—¥å¸¸å®ä¹ ", "å…¶ä»–"]
    if tag_dimensions["recruitType"] not in valid_recruit_types:
        tag_dimensions["recruitType"] = "å…¶ä»–"
    
    # æ„å»ºfinal payload
    return {
        "title": processed["title"],
        "originalContent": raw_data.get("originalContentHtml", ""),
        "processedContent": processed["processedContent"],
        "company": processed["company"],
        "role": processed["role"],
        "difficulty": int(processed["difficulty"]),
        "tags": list(processed["tags"]),  # ä¿ç•™å‘åå…¼å®¹
        "tagDimensions": tag_dimensions,  # æ–°å¢ç»“æ„åŒ–æ ‡ç­¾
        "comments": [],
        "usefulVotes": 0,
        "uselessVotes": 0,
        "shareCount": 0,
        "isAnonymous": True
    }

# ==================== HTMLè§£æ ====================

def parse_html(html_path: Path) -> Dict[str, Any]:
    """è§£æå•ä¸ªHTMLæ–‡ä»¶ä¸ºraw JSON"""
    raw_html = html_path.read_text(encoding="utf-8", errors="ignore")
    soup = BeautifulSoup(raw_html, "lxml")
    
    # ç§»é™¤anti-crawlingå…ƒç´ 
    for node in soup.select(".jammer"):
        node.decompose()
    
    # æå–æ ‡é¢˜
    title_node = soup.select_one(".thread_subject")
    title = title_node.get_text(" ", strip=True) if title_node else (soup.title.get_text(strip=True) if soup.title else "æœªå‘½åé¢ç»")
    
    # æå–æ—¶é—´
    time_node = soup.select_one(".post_time")
    publish_time_raw = time_node.get_text(" ", strip=True) if time_node else ""
    
    # æå–æ­£æ–‡
    body_node = soup.select_one(".article_body")
    if body_node:
        body_html = str(body_node)
    else:
        body_html = str(soup.body) if soup.body else raw_html
    
    body_text = BeautifulSoup(body_html, "lxml").get_text("\n", strip=True)
    
    # æå–ID
    m = re.search(r"(\d+)", html_path.name)
    post_id = m.group(1) if m else html_path.stem
    
    return {
        "id": post_id,
        "sourceFile": html_path.name,
        "title": title,
        "publishTimeRaw": publish_time_raw,
        "originalContentHtml": body_html,
        "originalContentText": body_text,
    }

# ==================== çŠ¶æ€ç®¡ç†ï¼ˆå¹‚ç­‰å»é‡ï¼‰====================

def init_state_db(state_db_path: Path) -> sqlite3.Connection:
    """åˆå§‹åŒ–çŠ¶æ€æ•°æ®åº“"""
    conn = sqlite3.connect(str(state_db_path))
    conn.execute("""
        CREATE TABLE IF NOT EXISTS processing_state (
            content_hash TEXT PRIMARY KEY,
            status TEXT NOT NULL,
            file_id TEXT,
            error_reason TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    conn.execute("CREATE INDEX IF NOT EXISTS idx_status ON processing_state(status)")
    conn.commit()
    return conn

def compute_content_hash(html_path: Path) -> str:
    """è®¡ç®—HTMLæ–‡ä»¶å†…å®¹hashï¼ˆç”¨äºå»é‡ï¼‰"""
    content = html_path.read_bytes()
    return hashlib.sha256(content).hexdigest()

def is_content_already_processed(processed_content: str) -> bool:
    """AIæ£€æµ‹processedContentæ˜¯å¦å·²è¢«æ¸…æ´—è¿‡"""
    if not processed_content or len(processed_content.strip()) < 100:
        return False
    
    # æ£€æŸ¥æ¸…æ´—åçš„ç‰¹å¾ï¼š
    # 1. åŒ…å«Markdownæ ¼å¼ï¼ˆ##æ ‡é¢˜ï¼‰
    # 2. ä¸åŒ…å«HTMLæ ‡ç­¾ï¼ˆ<div, <br/>ç­‰ï¼‰
    # 3. ä¸åŒ…å«åŠ å¯†æ•°å­—ï¼ˆè ¡å£ã€æ•£æ•£ç­‰ï¼‰
    # 4. ç»“æ„æ¸…æ™°ï¼ˆåŒ…å«åˆ†æ®µï¼‰
    has_markdown = "##" in processed_content
    has_html = bool(re.search(r"<[a-z][^>]*>", processed_content, re.I))
    has_encrypted = bool(re.search(r"[è ¡æ•£åˆ©è€³é…’ä¼è¡£ç§»ä½°åè´°å£¹]|[\u4e00\u4e8c\u4e09\u56db\u4e94\u516d\u4e03\u516b\u4e5d\u5341]+[å£æ•£æµå‡Œå°”ä¼]", processed_content))
    has_structure = "\n\n" in processed_content or processed_content.count("\n") > 5
    
    return has_markdown and not has_html and not has_encrypted and has_structure


def update_state(conn: sqlite3.Connection, content_hash: str, status: str, file_id: Optional[str] = None, error_reason: Optional[str] = None):
    """æ›´æ–°å¤„ç†çŠ¶æ€"""
    conn.execute("""
        INSERT OR REPLACE INTO processing_state 
        (content_hash, status, file_id, error_reason, updated_at)
        VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)
    """, (content_hash, status, file_id, error_reason))
    conn.commit()

# ==================== åç«¯å¯¼å…¥ ====================

def register_user(api_base: str, name: str, email: str, password: str):
    """æ³¨å†Œç”¨æˆ·ï¼ˆå¿½ç•¥é”™è¯¯ï¼‰"""
    try:
        requests.post(
            f"{api_base}/api/auth/register",
            json={"name": name, "email": email, "password": password},
            timeout=10
        )
    except:
        pass

def login(api_base: str, email: str, password: str) -> str:
    """ç™»å½•è·å–token"""
    response = requests.post(
        f"{api_base}/api/auth/login",
        json={"email": email, "password": password},
        timeout=10
    )
    response.raise_for_status()
    data = response.json()
    token = data.get("token") or data.get("accessToken") or data.get("jwt")
    if not token:
        raise RuntimeError(f"ç™»å½•æˆåŠŸä½†æœªè¿”å›token: {data}")
    return token

def upload_to_backend(api_base: str, token: str, payload: Dict[str, Any]) -> Dict[str, Any]:
    """ä¸Šä¼ åˆ°åç«¯"""
    response = requests.post(
        f"{api_base}/api/posts",
        headers={"Authorization": f"Bearer {token}"},
        json=payload,
        timeout=API_TIMEOUT
    )
    response.raise_for_status()
    return response.json()

# ==================== ä¸»æµç¨‹ ====================

def run_pipeline(html_dir: Path, out_dir: Path, api_base: Optional[str] = None, 
                 email: Optional[str] = None, password: Optional[str] = None):
    """è¿è¡Œpipelineä¸»æµç¨‹"""
    
    # 1. AI-gateï¼šæ£€æŸ¥AI API
    ai_available, ai_msg = check_ai_api()
    if not ai_available:
        print(f"âŒ {ai_msg}")
        print("\nâš ï¸  Pipelineè¦æ±‚å¿…é¡»é…ç½®AI APIæ‰èƒ½è¿è¡Œã€‚")
        print("   è¯·è®¾ç½®ç¯å¢ƒå˜é‡ï¼š")
        print("   export QWEN_API_KEY='sk-...'  # æˆ–")
        print("   export API_KEY='your-gemini-key'")
        sys.exit(1)
    
    print(f"âœ… {ai_msg} (ä½¿ç”¨ {AI_TYPE.upper()} API)")
    
    # 2. åˆ›å»ºè¾“å‡ºç›®å½•
    final_dir = out_dir / "final"
    bad_dir = out_dir / "bad"
    final_dir.mkdir(parents=True, exist_ok=True)
    bad_dir.mkdir(parents=True, exist_ok=True)
    
    # 3. åˆå§‹åŒ–çŠ¶æ€æ•°æ®åº“
    state_db_path = out_dir / "state.sqlite"
    state_conn = init_state_db(state_db_path)
    
    # 4. æŸ¥æ‰¾HTMLæ–‡ä»¶
    html_files = sorted(html_dir.glob("*.html"))
    if not html_files:
        print(f"âš ï¸  æœªæ‰¾åˆ°HTMLæ–‡ä»¶: {html_dir}")
        return
    
    print(f"\nğŸ“ æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶")
    print(f"âš¡ ä½¿ç”¨å¹¶å‘æ•°: {CONCURRENCY} (å¯é€šè¿‡ç¯å¢ƒå˜é‡ CONCURRENCY è°ƒæ•´)")
    
    # 5. å¤„ç†æ¯ä¸ªæ–‡ä»¶ï¼ˆå¹¶å‘å¤„ç†ï¼‰
    stats = {"total": len(html_files), "ok": 0, "bad": 0, "skipped": 0}
    stats_lock = Lock()  # ç”¨äºçº¿ç¨‹å®‰å…¨çš„ç»Ÿè®¡æ›´æ–°
    state_lock = Lock()  # çŠ¶æ€æ•°æ®åº“é”
    
    def process_single_file(html_path: Path, index: int) -> Tuple[str, str, Optional[str]]:
        """å¤„ç†å•ä¸ªHTMLæ–‡ä»¶ï¼ˆç”¨äºå¹¶å‘ï¼‰"""
        result_type = None
        result_msg = ""
        file_id = None
        
        try:
            # è®¡ç®—å†…å®¹hashï¼ˆç”¨äºå»é‡ï¼‰
            content_hash = compute_content_hash(html_path)
            
            # æ­¥éª¤1: æ£€æŸ¥hashæ˜¯å¦å·²å¤„ç†ï¼ˆå¿«é€Ÿæ£€æŸ¥çŠ¶æ€æ•°æ®åº“ï¼‰
            with state_lock:
                cursor = state_conn.execute(
                    "SELECT status, error_reason, file_id FROM processing_state WHERE content_hash = ?",
                    (content_hash,)
                )
                state_row = cursor.fetchone()
            
            prev_error = None
            if state_row:
                status, error_reason, saved_file_id = state_row
                if status == "ok" and saved_file_id:
                    # éªŒè¯finalæ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨ä¸”æœ‰æ•ˆ
                    final_path = final_dir / f"{saved_file_id}.json"
                    if final_path.exists():
                        try:
                            final_data = json.loads(final_path.read_text(encoding="utf-8"))
                            processed = final_data.get("processedContent", "")
                            # AIæ£€æµ‹æ˜¯å¦çœŸçš„å·²æ¸…æ´—
                            if is_content_already_processed(processed):
                                with stats_lock:
                                    stats["skipped"] += 1
                                return ("skipped", f"â­ï¸  å·²å¤„ç†è¿‡ï¼Œè·³è¿‡ï¼ˆcontent_hash: {content_hash[:8]}...ï¼‰", None)
                        except:
                            pass  # æ–‡ä»¶æŸåï¼Œé‡æ–°å¤„ç†
                elif status == "bad":
                    prev_error = error_reason
            
            # æ­¥éª¤2: è§£æHTML
            try:
                raw_data = parse_html(html_path)
                if not raw_data.get("title") or not raw_data.get("originalContentText"):
                    raise ValueError("è§£æå¤±è´¥ï¼šç¼ºå°‘titleæˆ–content")
                file_id = raw_data["id"]
            except Exception as e:
                error_msg = str(e)
                error_path = bad_dir / f"{html_path.stem}.error.txt"
                error_path.write_text(f"{html_path}\n{type(e).__name__}: {error_msg}\n", encoding="utf-8")
                with state_lock:
                    update_state(state_conn, content_hash, "bad", html_path.stem, error_msg[:500])
                with stats_lock:
                    stats["bad"] += 1
                return ("bad", f"âŒ HTMLè§£æå¤±è´¥: {error_msg[:100]}", None)
            
            # æ­¥éª¤3: å†æ¬¡æ£€æŸ¥ï¼ˆåŸºäºfile_idæ£€æŸ¥finalæ–‡ä»¶ï¼‰
            final_path = final_dir / f"{file_id}.json"
            if final_path.exists():
                try:
                    final_data = json.loads(final_path.read_text(encoding="utf-8"))
                    processed = final_data.get("processedContent", "")
                    if is_content_already_processed(processed):
                        with state_lock:
                            update_state(state_conn, content_hash, "ok", file_id)
                        with stats_lock:
                            stats["skipped"] += 1
                        return ("skipped", f"â­ï¸  å·²å¤„ç†è¿‡ï¼Œè·³è¿‡ï¼ˆfinalæ–‡ä»¶å·²å­˜åœ¨ä¸”æœ‰æ•ˆï¼‰", None)
                except:
                    pass  # æ–‡ä»¶æŸåï¼Œé‡æ–°å¤„ç†
            
            if prev_error:
                pass  # ä¹‹å‰å¤±è´¥ï¼Œé‡è¯•
            
            # æ­¥éª¤4: AIæ¸…æ´—
            final_data = process_with_ai(raw_data)
            
            # æ­¥éª¤5: éªŒè¯å¿…éœ€å­—æ®µ
            required = ["title", "processedContent", "company", "role", "difficulty", "tags"]
            missing = [f for f in required if not final_data.get(f)]
            if missing:
                raise ValueError(f"æœ€ç»ˆæ•°æ®ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing}")
            
            # æ­¥éª¤6: ä¿å­˜final JSON
            final_path.write_text(json.dumps(final_data, ensure_ascii=False, indent=2), encoding="utf-8")
            
            # æ­¥éª¤7: æ›´æ–°çŠ¶æ€
            with state_lock:
                update_state(state_conn, content_hash, "ok", file_id)
            with stats_lock:
                stats["ok"] += 1
            
            return ("ok", f"âœ… å¤„ç†æˆåŠŸï¼ˆä¿å­˜åˆ°: {final_path.name}ï¼‰", file_id)
            
        except Exception as e:
            error_msg = str(e)
            file_id = html_path.stem
            error_path = bad_dir / f"{file_id}.error.txt"
            error_path.write_text(f"{html_path}\n{type(e).__name__}: {error_msg}\n", encoding="utf-8")
            
            with state_lock:
                update_state(state_conn, content_hash, "bad", file_id, error_msg[:500])
            with stats_lock:
                stats["bad"] += 1
            
            return ("bad", f"âŒ å¤„ç†å¤±è´¥: {error_msg[:100]}", None)
    
    # å¹¶å‘å¤„ç†æ–‡ä»¶
    with ThreadPoolExecutor(max_workers=CONCURRENCY) as executor:
        futures = {executor.submit(process_single_file, html_path, i+1): (html_path, i+1) 
                   for i, html_path in enumerate(html_files)}
        
        completed = 0
        for future in as_completed(futures):
            completed += 1
            html_path, index = futures[future]
            try:
                result_type, result_msg, file_id = future.result()
                if result_type != "skipped":  # è·³è¿‡çš„ä¸æ‰“å°ï¼ˆå¤ªå¤šï¼‰
                    print(f"[{index}/{stats['total']}] {result_msg}")
                
                # æ¯10ä¸ªæ–‡ä»¶æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if completed % 10 == 0:
                    with stats_lock:
                        print(f"\nğŸ“Š è¿›åº¦: {completed}/{stats['total']} (æˆåŠŸ: {stats['ok']}, å¤±è´¥: {stats['bad']}, è·³è¿‡: {stats['skipped']})")
            except Exception as e:
                print(f"[{index}/{stats['total']}] âŒ å¤„ç†å¼‚å¸¸: {e}")
    
    
    # 6. è¾“å‡ºç»Ÿè®¡
    print(f"\n{'='*50}")
    print(f"ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡ï¼š")
    print(f"   æ€»è®¡: {stats['total']} ä¸ªæ–‡ä»¶")
    print(f"   âœ… æˆåŠŸ: {stats['ok']} ä¸ª")
    print(f"   âŒ å¤±è´¥: {stats['bad']} ä¸ª")
    print(f"   â­ï¸  è·³è¿‡: {stats['skipped']} ä¸ªï¼ˆå·²å¤„ç†è¿‡ï¼‰")
    print(f"\nè¾“å‡ºç›®å½•ï¼š")
    print(f"   Final JSON: {final_dir}")
    print(f"   å¤±è´¥è®°å½•: {bad_dir}")
    print(f"   çŠ¶æ€æ•°æ®åº“: {state_db_path}")
    
    state_conn.close()

# ==================== å‘½ä»¤è¡Œå…¥å£ ====================

def main():
    parser = argparse.ArgumentParser(description="HH Pipeline - HTMLé¢ç»å¤„ç†æµç¨‹")
    subparsers = parser.add_subparsers(dest="command", help="å‘½ä»¤")
    
    # runå‘½ä»¤
    run_parser = subparsers.add_parser("run", help="è¿è¡Œpipeline")
    run_parser.add_argument("--html-dir", required=True, help="HTMLæ–‡ä»¶ç›®å½•")
    run_parser.add_argument("--out-dir", default="./out", help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ./outï¼‰")
    run_parser.add_argument("--api-base", help="åç«¯APIåœ°å€ï¼ˆå¯é€‰ï¼Œç”¨äºä¸Šä¼ ï¼‰")
    run_parser.add_argument("--email", help="ç™»å½•é‚®ç®±ï¼ˆä¸--api-baseä¸€èµ·ä½¿ç”¨ï¼‰")
    run_parser.add_argument("--password", help="ç™»å½•å¯†ç ï¼ˆä¸--api-baseä¸€èµ·ä½¿ç”¨ï¼‰")
    
    args = parser.parse_args()
    
    if args.command == "run":
        html_dir = Path(args.html_dir)
        if not html_dir.exists():
            print(f"âŒ HTMLç›®å½•ä¸å­˜åœ¨: {html_dir}")
            sys.exit(1)
        
        out_dir = Path(args.out_dir)
        
        # éªŒè¯ä¸Šä¼ å‚æ•°
        if args.api_base and (not args.email or not args.password):
            print("âŒ ä½¿ç”¨--api-baseæ—¶å¿…é¡»åŒæ—¶æä¾›--emailå’Œ--password")
            sys.exit(1)
        
        run_pipeline(html_dir, out_dir, args.api_base, args.email, args.password)
    else:
        parser.print_help()

if __name__ == "__main__":
    main()

