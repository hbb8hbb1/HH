#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç°æœ‰æ•°æ®è¿ç§»è„šæœ¬ - æ–¹æ¡ˆä¸‰ï¼ˆæ··åˆæ–¹æ¡ˆï¼‰

åŠŸèƒ½ï¼š
1. é˜¶æ®µ1ï¼šè§„åˆ™æ˜ å°„ - ä»ç°æœ‰å­—æ®µï¼ˆtitle, tags, role, companyï¼‰æ¨æ–­ tagDimensions
2. é˜¶æ®µ2ï¼šAIè¡¥å…… - å¯¹ä¸ç¡®å®šçš„æ•°æ®ä½¿ç”¨AIæå– tagDimensions
3. ç»Ÿè®¡å’ŒæŠ¥å‘Š - æ˜¾ç¤ºè¿ç§»è¿›åº¦å’Œè´¨é‡

ä½¿ç”¨æ–¹æ³•ï¼š
    # åªè¿è¡Œè§„åˆ™æ˜ å°„ï¼ˆå¿«é€Ÿï¼‰
    python migrate_existing_data.py --mode rules-only
    
    # è¿è¡Œè§„åˆ™æ˜ å°„ + AIè¡¥å……ï¼ˆå®Œæ•´ï¼‰
    python migrate_existing_data.py --mode full
    
    # åªè¿è¡ŒAIè¡¥å……ï¼ˆå¯¹è§„åˆ™æ˜ å°„åä»æœ‰ç¼ºå¤±çš„æ•°æ®ï¼‰
    python migrate_existing_data.py --mode ai-only
"""

import argparse
import os
import re
import sys
from typing import Dict, Any, List, Optional, Tuple
from pymongo import MongoClient
from pymongo.errors import ConnectionFailure

# å¯¼å…¥ pipeline çš„ AI å¤„ç†é€»è¾‘
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
try:
    from pipeline import call_qwen_api, call_gemini_api
    # è·å–AIé…ç½®
    QWEN_API_KEY = os.environ.get("QWEN_API_KEY")
    GEMINI_API_KEY = os.environ.get("API_KEY") or os.environ.get("GEMINI_API_KEY")
    AI_TYPE = "qwen" if QWEN_API_KEY else ("gemini" if GEMINI_API_KEY else None)
except ImportError:
    print("âš ï¸  æ— æ³•å¯¼å…¥pipelineæ¨¡å—ï¼ŒAIè¡¥å……åŠŸèƒ½å°†ä¸å¯ç”¨")
    AI_TYPE = None

# ==================== é…ç½® ====================

# MongoDB è¿æ¥
MONGO_URI = os.environ.get("MONGO_URI", "mongodb://localhost:27017/offermagnet")
DB_NAME = "offermagnet"
COLLECTION_NAME = "posts"

# åœ°ç‚¹å…³é”®è¯æ˜ å°„
LOCATION_KEYWORDS = {
    "åŒ—äº¬": ["åŒ—äº¬", "beijing", "bj"],
    "ä¸Šæµ·": ["ä¸Šæµ·", "shanghai", "sh"],
    "æ·±åœ³": ["æ·±åœ³", "shenzhen", "sz"],
    "æ­å·": ["æ­å·", "hangzhou", "hz"],
    "å¹¿å·": ["å¹¿å·", "guangzhou", "gz"],
    "æˆéƒ½": ["æˆéƒ½", "chengdu", "cd"],
    "æ–°åŠ å¡": ["æ–°åŠ å¡", "singapore", "sg"],
    "ç¡…è°·": ["ç¡…è°·", "silicon valley", "sv", "san francisco", "sf", "bay area"],
    "çº½çº¦": ["çº½çº¦", "new york", "ny"],
    "ä¼¦æ•¦": ["ä¼¦æ•¦", "london"],
    "é¦™æ¸¯": ["é¦™æ¸¯", "hong kong", "hk"]
}

# æ‹›è˜ç±»å‹å…³é”®è¯æ˜ å°„
RECRUIT_TYPE_KEYWORDS = {
    "æ ¡æ‹›": ["æ ¡æ‹›", "æ ¡å›­æ‹›è˜", "åº”å±Š", "new grad", "campus", "åº”å±Šç”Ÿ"],
    "ç¤¾æ‹›": ["ç¤¾æ‹›", "ç¤¾ä¼šæ‹›è˜", "experienced", "ç¤¾æ‹›"],
    "æš‘æœŸå®ä¹ ": ["æš‘æœŸå®ä¹ ", "summer intern", "summer internship"],
    "æ—¥å¸¸å®ä¹ ": ["æ—¥å¸¸å®ä¹ ", "intern", "internship", "å®ä¹ "]
}

# æŠ€æœ¯æ ˆå…³é”®è¯ï¼ˆç”¨äºä»tagsä¸­æå–ï¼‰
TECH_KEYWORDS = [
    "React", "Vue", "Angular", "TypeScript", "JavaScript", "Python", "Java", "Go", "C++", "C#",
    "Node.js", "Spring", "Django", "Flask", "PyTorch", "TensorFlow", "Keras", "Scikit-learn",
    "MongoDB", "MySQL", "PostgreSQL", "Redis", "Kafka", "Docker", "Kubernetes",
    "AWS", "Azure", "GCP", "Linux", "Git", "CI/CD"
]

# éƒ¨é—¨ç±»åˆ«æ˜ å°„ï¼ˆä»roleæ¨æ–­ï¼‰
CATEGORY_KEYWORDS = {
    "ç ”å‘": ["engineer", "developer", "å¼€å‘", "å·¥ç¨‹å¸ˆ", "software", "ç ”å‘"],
    "ç®—æ³•": ["algorithm", "ml", "machine learning", "ai", "ç®—æ³•", "æœºå™¨å­¦ä¹ ", "data scientist", "æ•°æ®ç§‘å­¦"],
    "äº§å“": ["product", "pm", "äº§å“", "product manager"],
    "è®¾è®¡": ["design", "designer", "è®¾è®¡", "ui", "ux"],
    "è¿è¥": ["operation", "è¿è¥", "operation manager"],
    "å¸‚åœº": ["marketing", "å¸‚åœº", "marketing manager"]
}

# å­è§’è‰²æ˜ å°„ï¼ˆä»roleæˆ–tagsæ¨æ–­ï¼‰
SUBROLE_KEYWORDS = {
    "å‰ç«¯": ["frontend", "å‰ç«¯", "react", "vue", "angular", "web"],
    "åç«¯": ["backend", "åç«¯", "server", "api", "java", "python", "go"],
    "ç§»åŠ¨ç«¯": ["mobile", "ios", "android", "ç§»åŠ¨", "app"],
    "å…¨æ ˆ": ["fullstack", "å…¨æ ˆ", "full stack"],
    "æµ‹è¯•": ["test", "qa", "æµ‹è¯•", "quality"],
    "è¿ç»´": ["devops", "sre", "è¿ç»´", "infrastructure"],
    "å¤§æ•°æ®": ["big data", "å¤§æ•°æ®", "hadoop", "spark"],
    "æ¶æ„": ["architect", "æ¶æ„", "system design"],
    "ç³»ç»Ÿè®¾è®¡": ["system design", "ç³»ç»Ÿè®¾è®¡", "distributed"],
    "æœºå™¨å­¦ä¹ ": ["machine learning", "ml", "æœºå™¨å­¦ä¹ ", "deep learning"],
    "CV": ["cv", "computer vision", "è®¡ç®—æœºè§†è§‰", "å›¾åƒ"],
    "NLP": ["nlp", "natural language", "è‡ªç„¶è¯­è¨€", "æ–‡æœ¬"],
    "æ¨èç³»ç»Ÿ": ["recommendation", "æ¨è", "recommender"],
    "å¼ºåŒ–å­¦ä¹ ": ["reinforcement learning", "å¼ºåŒ–å­¦ä¹ ", "rl"],
    "å¤§æ¨¡å‹/LLM": ["llm", "large language model", "å¤§æ¨¡å‹", "gpt", "bert"]
}

# ==================== è§„åˆ™æ˜ å°„é€»è¾‘ ====================

def extract_location(title: str, tags: List[str]) -> str:
    """ä»titleå’Œtagsä¸­æå–åœ°ç‚¹"""
    text = (title + " " + " ".join(tags)).lower()
    
    for location, keywords in LOCATION_KEYWORDS.items():
        for keyword in keywords:
            if keyword.lower() in text:
                return location
    
    return ""

def extract_recruit_type(title: str, tags: List[str]) -> str:
    """ä»titleå’Œtagsä¸­æå–æ‹›è˜ç±»å‹"""
    text = (title + " " + " ".join(tags)).lower()
    
    # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥ï¼ˆæ ¡æ‹› > ç¤¾æ‹› > å®ä¹ ï¼‰
    for recruit_type, keywords in RECRUIT_TYPE_KEYWORDS.items():
        for keyword in keywords:
            if keyword.lower() in text:
                return recruit_type
    
    return "å…¶ä»–"

def extract_technologies(tags: List[str]) -> List[str]:
    """ä»tagsä¸­æå–æŠ€æœ¯æ ˆ"""
    technologies = []
    tag_text = " ".join(tags).lower()
    
    for tech in TECH_KEYWORDS:
        if tech.lower() in tag_text:
            technologies.append(tech)
    
    # å»é‡å¹¶ä¿æŒé¡ºåº
    seen = set()
    result = []
    for tech in technologies:
        tech_lower = tech.lower()
        if tech_lower not in seen:
            seen.add(tech_lower)
            result.append(tech)
    
    return result

def extract_category(role: str) -> str:
    """ä»roleä¸­æ¨æ–­éƒ¨é—¨ç±»åˆ«"""
    if not role:
        return ""
    
    role_lower = role.lower()
    
    for category, keywords in CATEGORY_KEYWORDS.items():
        for keyword in keywords:
            if keyword.lower() in role_lower:
                return category
    
    return ""

def extract_sub_role(role: str, tags: List[str]) -> str:
    """ä»roleå’Œtagsä¸­æ¨æ–­å­è§’è‰²"""
    text = (role + " " + " ".join(tags)).lower()
    
    for sub_role, keywords in SUBROLE_KEYWORDS.items():
        for keyword in keywords:
            if keyword.lower() in text:
                return sub_role
    
    return ""

def extract_custom_tags(tags: List[str], technologies: List[str]) -> List[str]:
    """æå–è‡ªå®šä¹‰æ ‡ç­¾ï¼ˆæ’é™¤æŠ€æœ¯æ ˆå’Œç»´åº¦æ ‡ç­¾ï¼‰"""
    custom = []
    tech_lower = [t.lower() for t in technologies]
    
    # æ’é™¤æŠ€æœ¯æ ˆ
    for tag in tags:
        tag_lower = tag.lower()
        if tag_lower not in tech_lower:
            # æ’é™¤ç»´åº¦æ ‡ç­¾ï¼ˆåœ°ç‚¹ã€æ‹›è˜ç±»å‹ç­‰ï¼‰
            is_dimension_tag = False
            for location in LOCATION_KEYWORDS.keys():
                if location.lower() in tag_lower or tag_lower in location.lower():
                    is_dimension_tag = True
                    break
            for recruit_type in RECRUIT_TYPE_KEYWORDS.keys():
                if recruit_type.lower() in tag_lower or tag_lower in recruit_type.lower():
                    is_dimension_tag = True
                    break
            
            if not is_dimension_tag:
                custom.append(tag)
    
    return custom[:5]  # æœ€å¤šä¿ç•™5ä¸ªè‡ªå®šä¹‰æ ‡ç­¾

def rule_based_migration(post: Dict[str, Any]) -> Dict[str, Any]:
    """è§„åˆ™æ˜ å°„ï¼šä»ç°æœ‰å­—æ®µæ¨æ–­ tagDimensions"""
    title = post.get("title", "")
    tags = post.get("tags", [])
    role = post.get("role", "")
    company = post.get("company", "")
    
    # æå–å„ä¸ªç»´åº¦
    location = extract_location(title, tags)
    recruit_type = extract_recruit_type(title, tags)
    technologies = extract_technologies(tags)
    category = extract_category(role)
    sub_role = extract_sub_role(role, tags)
    custom = extract_custom_tags(tags, technologies)
    
    # æ„å»º tagDimensions
    tag_dimensions = {
        "technologies": technologies,
        "recruitType": recruit_type if recruit_type else "å…¶ä»–",
        "location": location,
        "category": category,
        "subRole": sub_role,
        "custom": custom
    }
    
    return tag_dimensions

# ==================== AIè¡¥å……é€»è¾‘ ====================

def build_ai_prompt_for_dimensions(title: str, processed_content: str, existing_dims: Dict[str, Any]) -> str:
    """æ„å»ºAIæç¤ºè¯ï¼Œåªæå–ç¼ºå¤±çš„ç»´åº¦"""
    missing = []
    if not existing_dims.get("category"):
        missing.append("category (éƒ¨é—¨ç±»åˆ«ï¼šç ”å‘ã€ç®—æ³•ã€äº§å“ç­‰)")
    if not existing_dims.get("subRole"):
        missing.append("subRole (å­è§’è‰²ï¼šå‰ç«¯ã€åç«¯ã€æœºå™¨å­¦ä¹ ç­‰)")
    if not existing_dims.get("location"):
        missing.append("location (åœ°ç‚¹ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€ç¡…è°·ç­‰)")
    if not existing_dims.get("recruitType") or existing_dims.get("recruitType") == "å…¶ä»–":
        missing.append("recruitType (æ‹›è˜ç±»å‹ï¼šæ ¡æ‹›ã€ç¤¾æ‹›ã€æš‘æœŸå®ä¹ ã€æ—¥å¸¸å®ä¹ )")
    
    if not missing:
        return None  # æ²¡æœ‰ç¼ºå¤±çš„ç»´åº¦ï¼Œä¸éœ€è¦AIå¤„ç†
    
    return f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•°æ®æ ‡æ³¨å‘˜ã€‚è¯·ä»ä»¥ä¸‹é¢ç»å†…å®¹ä¸­æå–ç¼ºå¤±çš„ç»´åº¦ä¿¡æ¯ã€‚

æ ‡é¢˜ï¼š{title}

å†…å®¹ï¼ˆå‰2000å­—ï¼‰ï¼š
{processed_content[:2000]}

å½“å‰å·²æœ‰çš„ tagDimensionsï¼š
{existing_dims}

è¯·åªæå–ä»¥ä¸‹ç¼ºå¤±çš„ç»´åº¦ï¼ˆå¦‚æœæ— æ³•ç¡®å®šï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²æˆ–é»˜è®¤å€¼ï¼‰ï¼š
{', '.join(missing)}

è¿”å› JSON æ ¼å¼ï¼ŒåªåŒ…å«ç¼ºå¤±çš„ç»´åº¦å­—æ®µï¼Œä¾‹å¦‚ï¼š
{{
  "category": "ç ”å‘",
  "subRole": "å‰ç«¯",
  "location": "åŒ—äº¬",
  "recruitType": "æ ¡æ‹›"
}}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""

def ai_supplement_dimensions(post: Dict[str, Any], existing_dims: Dict[str, Any]) -> Dict[str, Any]:
    """ä½¿ç”¨AIè¡¥å……ç¼ºå¤±çš„ç»´åº¦"""
    if not AI_TYPE:
        return existing_dims  # AIæœªé…ç½®
    
    title = post.get("title", "")
    processed_content = post.get("processedContent", "")
    
    if not processed_content or len(processed_content) < 50:
        return existing_dims  # æ²¡æœ‰å†…å®¹ï¼Œæ— æ³•AIå¤„ç†
    
    prompt = build_ai_prompt_for_dimensions(title, processed_content, existing_dims)
    if not prompt:
        return existing_dims  # æ²¡æœ‰ç¼ºå¤±çš„ç»´åº¦
    
    try:
        if AI_TYPE == "qwen":
            result = call_qwen_api(prompt)
        elif AI_TYPE == "gemini":
            result = call_gemini_api(prompt)
        else:
            return existing_dims
        
        # åˆå¹¶AIç»“æœåˆ°ç°æœ‰ç»´åº¦
        updated_dims = existing_dims.copy()
        for key, value in result.items():
            if key in updated_dims:
                # åªæ›´æ–°ç©ºå€¼æˆ–é»˜è®¤å€¼
                if not updated_dims[key] or updated_dims[key] == "å…¶ä»–":
                    if value:  # AIè¿”å›äº†æœ‰æ•ˆå€¼
                        updated_dims[key] = value
        
        return updated_dims
    except Exception as e:
        print(f"âš ï¸  AIå¤„ç†å¤±è´¥: {e}")
        return existing_dims

# ==================== ä¸»æµç¨‹ ====================

def migrate_posts(mode: str = "full", batch_size: int = 100):
    """è¿ç§»å¸–å­æ•°æ®"""
    print(f"ğŸ”— è¿æ¥MongoDB: {MONGO_URI}")
    try:
        client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
        client.server_info()  # æµ‹è¯•è¿æ¥
        db = client[DB_NAME]
        posts_collection = db[COLLECTION_NAME]
        print("âœ… MongoDBè¿æ¥æˆåŠŸ")
    except ConnectionFailure as e:
        print(f"âŒ MongoDBè¿æ¥å¤±è´¥: {e}")
        return
    
    # æŸ¥è¯¢éœ€è¦è¿ç§»çš„æ•°æ®ï¼ˆæ²¡æœ‰tagDimensionsæˆ–tagDimensionsä¸ºç©ºï¼‰
    query = {
        "$or": [
            {"tagDimensions": {"$exists": False}},
            {"tagDimensions": None},
            {"tagDimensions": {}}
        ]
    }
    
    total_count = posts_collection.count_documents(query)
    print(f"\nğŸ“Š æ‰¾åˆ° {total_count} æ¡éœ€è¦è¿ç§»çš„æ•°æ®")
    
    if total_count == 0:
        print("âœ… æ‰€æœ‰æ•°æ®å·²è¿ç§»å®Œæˆ")
        return
    
    # ç»Ÿè®¡
    stats = {
        "total": total_count,
        "rules_migrated": 0,
        "ai_supplemented": 0,
        "skipped": 0,
        "failed": 0
    }
    
    # æ‰¹é‡å¤„ç†
    cursor = posts_collection.find(query).batch_size(batch_size)
    
    for i, post in enumerate(cursor, 1):
        try:
            post_id = post.get("_id")
            
            # é˜¶æ®µ1ï¼šè§„åˆ™æ˜ å°„
            if mode in ["full", "rules-only"]:
                tag_dimensions = rule_based_migration(post)
                stats["rules_migrated"] += 1
            else:
                # ai-onlyæ¨¡å¼ï¼šå…ˆè·å–ç°æœ‰çš„tagDimensionsï¼ˆå¦‚æœæœ‰ï¼‰
                tag_dimensions = post.get("tagDimensions", {})
                if not tag_dimensions:
                    tag_dimensions = {
                        "technologies": [],
                        "recruitType": "å…¶ä»–",
                        "location": "",
                        "category": "",
                        "subRole": "",
                        "custom": []
                    }
            
            # é˜¶æ®µ2ï¼šAIè¡¥å……ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if mode in ["full", "ai-only"]:
                # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±çš„ç»´åº¦
                needs_ai = (
                    not tag_dimensions.get("category") or
                    not tag_dimensions.get("subRole") or
                    not tag_dimensions.get("location") or
                    tag_dimensions.get("recruitType") == "å…¶ä»–"
                )
                
                if needs_ai:
                    tag_dimensions = ai_supplement_dimensions(post, tag_dimensions)
                    stats["ai_supplemented"] += 1
            
            # æ›´æ–°æ•°æ®åº“
            posts_collection.update_one(
                {"_id": post_id},
                {"$set": {"tagDimensions": tag_dimensions}}
            )
            
            # è¿›åº¦æ˜¾ç¤º
            if i % 10 == 0 or i == total_count:
                print(f"  [{i}/{total_count}] âœ… å·²è¿ç§» (è§„åˆ™: {stats['rules_migrated']}, AI: {stats['ai_supplemented']})")
        
        except Exception as e:
            stats["failed"] += 1
            print(f"  [{i}/{total_count}] âŒ è¿ç§»å¤±è´¥: {e}")
    
    # è¾“å‡ºç»Ÿè®¡
    print(f"\nğŸ“Š è¿ç§»å®Œæˆ:")
    print(f"   âœ… è§„åˆ™æ˜ å°„: {stats['rules_migrated']} æ¡")
    print(f"   ğŸ¤– AIè¡¥å……: {stats['ai_supplemented']} æ¡")
    print(f"   âŒ å¤±è´¥: {stats['failed']} æ¡")
    
    # éªŒè¯å’Œç»Ÿè®¡
    remaining = posts_collection.count_documents(query)
    migrated = total_count - remaining
    print(f"\nâœ… æˆåŠŸè¿ç§»: {migrated}/{total_count} æ¡")
    if remaining > 0:
        print(f"âš ï¸  ä»æœ‰ {remaining} æ¡æ•°æ®æœªè¿ç§»")
    
    # æ•°æ®è´¨é‡è¯„ä¼°ï¼ˆä½¿ç”¨èšåˆæŸ¥è¯¢ï¼Œé¿å…æ¸¸æ ‡è¶…æ—¶ï¼‰
    print(f"\nğŸ“ˆ æ•°æ®è´¨é‡è¯„ä¼°:")
    try:
        # ä½¿ç”¨èšåˆç®¡é“ç»Ÿè®¡ï¼Œé¿å…æ¸¸æ ‡è¶…æ—¶
        pipeline = [
            {"$match": {"tagDimensions": {"$exists": True, "$ne": None, "$ne": {}}}},
            {"$project": {
                "has_category": {"$cond": [{"$ne": ["$tagDimensions.category", ""]}, 1, 0]},
                "has_subrole": {"$cond": [{"$ne": ["$tagDimensions.subRole", ""]}, 1, 0]},
                "has_location": {"$cond": [{"$ne": ["$tagDimensions.location", ""]}, 1, 0]},
                "has_recruit_type": {"$cond": [
                    {"$and": [
                        {"$ne": ["$tagDimensions.recruitType", ""]},
                        {"$ne": ["$tagDimensions.recruitType", "å…¶ä»–"]}
                    ]}, 1, 0]},
                "has_technologies": {"$cond": [
                    {"$gt": [{"$size": {"$ifNull": ["$tagDimensions.technologies", []]}}, 0]}, 1, 0]},
                "complete": {"$cond": [
                    {"$and": [
                        {"$ne": ["$tagDimensions.category", ""]},
                        {"$ne": ["$tagDimensions.subRole", ""]},
                        {"$ne": ["$tagDimensions.location", ""]}
                    ]}, 1, 0]}
            }},
            {"$group": {
                "_id": None,
                "total": {"$sum": 1},
                "has_category": {"$sum": "$has_category"},
                "has_subrole": {"$sum": "$has_subrole"},
                "has_location": {"$sum": "$has_location"},
                "has_recruit_type": {"$sum": "$has_recruit_type"},
                "has_technologies": {"$sum": "$has_technologies"},
                "complete": {"$sum": "$complete"}
            }}
        ]
        
        result = list(posts_collection.aggregate(pipeline))
        
        if result and result[0]:
            stats = result[0]
            total = stats.get("total", 0)
            
            if total > 0:
                print(f"   categoryå¡«å……ç‡: {stats['has_category']}/{total} ({stats['has_category']/total*100:.1f}%)")
                print(f"   subRoleå¡«å……ç‡: {stats['has_subrole']}/{total} ({stats['has_subrole']/total*100:.1f}%)")
                print(f"   locationå¡«å……ç‡: {stats['has_location']}/{total} ({stats['has_location']/total*100:.1f}%)")
                print(f"   recruitTypeå¡«å……ç‡: {stats['has_recruit_type']}/{total} ({stats['has_recruit_type']/total*100:.1f}%)")
                print(f"   technologieså¡«å……ç‡: {stats['has_technologies']}/{total} ({stats['has_technologies']/total*100:.1f}%)")
                print(f"   å®Œæ•´åº¦ï¼ˆcategory+subRole+locationï¼‰: {stats['complete']}/{total} ({stats['complete']/total*100:.1f}%)")
            else:
                print("   âš ï¸  æ²¡æœ‰æ‰¾åˆ°å·²è¿ç§»çš„æ•°æ®")
        else:
            print("   âš ï¸  æ•°æ®è´¨é‡è¯„ä¼°å¤±è´¥")
    except Exception as e:
        print(f"   âš ï¸  æ•°æ®è´¨é‡è¯„ä¼°å‡ºé”™: {e}")
        print("   ğŸ’¡ æ•°æ®å·²æˆåŠŸè¿ç§»ï¼Œå¯ä»¥æ‰‹åŠ¨éªŒè¯")

def main():
    parser = argparse.ArgumentParser(description="ç°æœ‰æ•°æ®è¿ç§»è„šæœ¬")
    parser.add_argument(
        "--mode",
        choices=["rules-only", "ai-only", "full"],
        default="full",
        help="è¿ç§»æ¨¡å¼: rules-only(ä»…è§„åˆ™æ˜ å°„), ai-only(ä»…AIè¡¥å……), full(å®Œæ•´æµç¨‹)"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=100,
        help="æ‰¹é‡å¤„ç†å¤§å°"
    )
    parser.add_argument(
        "--mongo-uri",
        type=str,
        default=None,
        help="MongoDBè¿æ¥URIï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡MONGO_URIï¼‰"
    )
    
    args = parser.parse_args()
    
    if args.mongo_uri:
        global MONGO_URI
        MONGO_URI = args.mongo_uri
    
    print("=" * 60)
    print("ğŸ“¦ ç°æœ‰æ•°æ®è¿ç§»è„šæœ¬ - æ–¹æ¡ˆä¸‰ï¼ˆæ··åˆæ–¹æ¡ˆï¼‰")
    print("=" * 60)
    print(f"æ¨¡å¼: {args.mode}")
    print(f"æ‰¹é‡å¤§å°: {args.batch_size}")
    print()
    
    migrate_posts(mode=args.mode, batch_size=args.batch_size)

if __name__ == "__main__":
    main()

