{
  "title": "Google 机器学习工程师面试复盘：五轮技术面与行为问题回顾",
  "originalContent": "<div class=\"article_body\"><td class=\"t_f\" id=\"postmessage_16282224\" itemprop=\"articleBody\">\n狗家申请的MLE，因为HR 回复慢中间拖了很久，估计她觉得对不起我所以直接帮我申请了Onsite. LOL<br/>\n<br/>\nVO 一共5轮：<br/>\n<span style=\"display:none\"></span>1. ML 相关，因为是MLE， 他有对应的Domain experty 让我选，： Recommendation System, CV, NLP, DNN, Audio. 我选了RS， 所以当时面试小哥问的是关于Collabrative filtering 的问题，我提出在只有interation history的前提下， 可以用matrix factorization. 他说好，那你就在白板上现写MF的代码， 我用的 pytorch也很快写出来了， 他又问，MF 如何处理新的items.当时我就蒙了，MF最大的问题就是cold start. 然后我就说可以train 一个 autoencoder for all items, 然后用autoencoder的middle layer as embedding 而不是直接用MF 的 item embedding,这样就算新的item也有对应的embedding。 他说是个办法。 请问一下大家MF对于 novel item 的正确打开方式到底是啥？<br/>\n<br/>\n2. coding: 垒砖块问题， N*3的房子， 有1*3， 2*3， 3*3的砖块，问一共有多少种垒法。 我知道这种问题需要用DP，但是我当时脑子黏住了，思路是对的，但是中间dp转换方程式半天没写对，最后还是面试官给了一个大大的HINT才好不容易对了。面试官人很好，但是我当时真是被自己蠢哭了。后来我写了一个O(N) 的，他问我如何提高，我是真不知道了。 <br/>\n<br/>\n3. coding: waitlist 问题，就是让你的waitlist实现add, remove, empty table 之类的功能。我就用了最简单的 dict() + list. 但是应该有更smart一点的办法吧，比如Linklist。小伙伴有什么想法吗？<br/>\n<br/>\n4. BP： 问的比较常规，conflict, ambiguity.还有两个假设问题，如果其他组加feature和你们的proJect 冲突了怎么办， 还有就是你组织游戏结果有些人来不了怎么办？<br/>\n<br/>\n5. coding: KNN, 给你一个target vector, 还有一组 vector, 找K nearest neighbor. <br/>\n<br/>\n总的下来感觉他们对于MLE没有像SDE 那么难的问题，但是他依旧会不断地追问你有没有提高的办法。 但是我还是被自己在第二轮的表现气哭了。昨天刚面完，不知道结局如何。生死有命富贵在天吧。求大米， 今年最后一个面试，不成功便来年再战吧~~<br/>\n<br/>\n<br/>\n<span style=\"display:none\"></span></td></div>",
  "processedContent": "## 基本信息（公司/岗位/结果/难度）\n- **公司**：Google\n- **岗位**：机器学习工程师（MLE）\n- **结果**：未提及/不明确\n- **难度**：4\n\n## 时间线\n- HR 回复较慢，中间等待时间较长。\n- 后续直接安排 Onsite 面试（推测为跳过部分初面环节）。\n- 面试共进行 5 轮，均为现场或视频形式（VO）。\n- 面试结束时间：约在提交面经的前一天（具体日期未提及）。\n\n## 面试过程\n### 第一轮：机器学习专业题（推荐系统方向）\n- 面试官允许候选人选择擅长领域，候选人选择推荐系统（RS）。\n- 问题围绕协同过滤展开，要求在仅有用户-物品交互历史的情况下建模。\n- 提出使用矩阵分解（Matrix Factorization, MF），并在白板上用 PyTorch 实现代码。\n- 进阶提问：如何处理新物品（cold start 问题）？\n- 候选人提出使用 Autoencoder 学习通用 item embedding，作为替代方案，面试官表示认可。\n\n### 第二轮：算法题（垒砖块问题）\n- 题目描述：一个 N×3 的房屋结构，可用 1×3、2×3、3×3 的砖块填充，求所有可能的垒法数量。\n- 思路正确，应使用动态规划（DP）解决。\n- DP 状态转移方程未能独立写出，依赖面试官提示才完成。\n- 最终实现 O(N) 解法，但被问及优化方式时未能进一步回答。\n\n### 第三轮：系统设计类编码题（候补列表实现）\n- 实现一个 waitlist（候补名单）系统，支持 add、remove、清空等功能。\n- 使用 dict() + list() 实现基础逻辑。\n- 面试中反思是否有更优数据结构，如链表（Linked List）等。\n\n### 第四轮：行为面试（Behavioral Questions）\n- 问题包括：如何处理冲突与模糊性（conflict & ambiguity）。\n- 场景假设题：\n  - 若其他团队新增功能与本项目冲突，如何应对？\n  - 组织团队活动时有人无法参加，如何协调？\n\n### 第五轮：算法题（KNN 实现）\n- 给定一个目标向量和一组候选向量，找出 K 个最近邻。\n- 考察距离计算与优先队列/排序实现。\n- 未提及具体实现细节与追问情况。\n\n## 题目总结\n- **机器学习理论与应用**：\n  - 协同过滤中的矩阵分解原理与实现\n  - 矩阵分解如何应对冷启动问题（尤其是新 item）\n  - 使用 Autoencoder 生成 item embedding 的思路\n\n- **算法编程题**：\n  1. N×3 房屋填砖问题 —— 动态规划建模\n  2. Waitlist 系统设计 —— 数据结构选择与操作实现\n  3. K近邻搜索（KNN）—— 向量距离计算与 Top-K 查找\n\n- **行为问题**：\n  - 如何处理跨团队功能冲突\n  - 团队协作中的不确定性与人员缺席问题\n  - 工作中的模糊性与决策能力\n\n## 个人总结（经验与建议）\n- Google 对 MLE 岗位的技术要求虽略低于 SDE，但仍重视深入追问与优化思维。\n- 面试官整体态度友好，愿意给予提示，但对核心问题仍要求清晰表达与实现。\n- 自我反思：第二轮 DP 题表现不佳，因紧张导致思路卡顿，提醒后续准备需加强高频 DP 题型训练。\n- 建议：\n  - 提前准备好 cold start 的多种解决方案（如 content-based initialization、meta-learning、hybrid models）。\n  - 编码题注重最优解与可扩展性讨论，即使完成也需准备“如何优化”类问题。\n  - 行为问题注意 STAR 结构化表达。\n- 心态调整重要，一场面试不代表全部，失败亦是积累。",
  "company": "Google",
  "role": "机器学习工程师",
  "difficulty": 4,
  "tags": [
    "机器学习工程师",
    "推荐系统",
    "动态规划",
    "行为面试",
    "系统设计",
    "KNN",
    "矩阵分解",
    "冷启动"
  ],
  "comments": [],
  "usefulVotes": 0,
  "uselessVotes": 0,
  "shareCount": 0,
  "isAnonymous": true
}