{
  "title": "狗家数据科学家面试详尽面经：统计、建模与编程实战",
  "originalContent": "<div class=\"article_body\"><td class=\"t_f\" id=\"postmessage_19932366\" itemprop=\"articleBody\">\n<br/>\n<span style=\"display:none\"></span>超详细  DS 面经，求大米！正在努力找工作上岸！<br/>\n<br/>\n<br/>\n总得来说面试题比较难，但是面试官都比较友善，也比较会引导（除了其中一轮）。感觉  家的面试很难准备，不像元宇宙有很多面经。感觉还是靠平时的积累。<br/>\n<br/>\n<font size=\"5\">Technical: Statistics</font><br/>\n<br/>\n<strong>Question 1: Assume we have a sample with 100 data points. The sample mean is 100, and margin of error is 10. The confidence interval is [70, 90]. The PM complains that the confidence interval is too wide. What can you do?</strong><br/>\n回答：可以考虑增大 sample size.<br/>\n<strong>Follow up: Let’s say we increase the sample size to 10000. How will the CI change? Can you think of other ways to make the CI narrower without increasing the sample size?</strong><br/>\n<span style=\"display:none\"></span>回答：增加 significance level 可以让 CI 变窄.<br/>\n<strong>Question 2:  Assume we have a linear model Y = X * b, where X = (X_1, X_2, …, X_m) and b = (b_0, b_1, …, b_m). Also we have n data points (y_i, x_i). How would you estimate b?</strong><br/>\n回答：We can use OLS assuming we have m &lt; n. Estimated b will be (X^T X)^{-1} X^T Y<br/>\nFollow up: Let’s assume we actually have more features than data points. That is m &gt; n. What would you do?<div id=\"1p3a-ad-thread-paragraph\" style=\"margin-top: 20px; margin-bottom: 20px;\"></div><br/>\n回答：A few options to consider. (1) Do we really need all m features? Consider feature selection before building the model using business context. (2) Consider regularization method such as lasso regression. (3) Upsample from existing observation to make n &gt; n.（我后来想了想其实这个不是很合理）(4) Try other methods like random forecasts.<br/>\n<strong>Question 3: If we want to know if some feature is relevant or not, what can we do?</strong><br/>\n回答：We can look at t-test result on a single beta coefficient.<br/>\nFollow-up: How do you construct the t-test? What’s the null and alternative hypothesis?<br/>\n回答：Null hypothesis is H_0: beta_i = 0, and alternative is H_a: beta_i \\ne 0.<br/>\nFollow-up: Why is it a t-distribution?<br/>\n回答：这题我愣了半天，不知道想考什么。我一开始说 CI looks like +/- 1.96 * (beta_hat / s.e. (beta_hat)), 然后后面那个东西服从 t- 分布。然后面试官问我“为什么？”我就说，因为 beta_hat 是正态分布，然后分母那个东西是 chi-square. 这个也可以推，比如 Var[beta_ols] = […] <a class=\"relatedlink\" href=\"https://link.1point3acres.com/?url=https%3A%2F%2Fwww.amazon.com%2Fs%3Fk%3DSigma\" target=\"_blank\">sigma</a>^2 […]^T，然后你可以证明对角线上的应该是 t 分布？后来他说 OK but what’s the intuition here? 我想了半天说，如果 standard error 已知的话就是 normal，但是我们不知道，所以需要估计，所以就不是 normal 了.<br/>\n<br/>\n<font size=\"5\">Technical: Data analysis and intuition I</font><br/>\n<br/>\n这一轮主要的问题是和 YouTube Music 那个手机应用有关系的。打开那个应用之后，上面会有几个建议用户听的 theme，比如 Relax, Workout 或者 Commute. 问题是：假设今天有律师过来说，很担心用户听 Commute list 的时候开车会更快。作为 DS 你会怎么做？<br/>\n我的回答是可以先考虑做一个 simple t-test 看一下听通勤歌单的人和不听通勤歌单的人之间是不是真的开车速度差很多。然后有时间的话，可以建模。感觉是个非常开放式的问题，没有什么正确答案。但是面试官会问得很细，比如“你用什么 population 建模”，“你的 data granularity 是什么”，“有的人刚开始通勤的时候听的是其他的歌单，开到一半才开始听通勤歌单，你会怎么处理”，“有人通勤的时候其实并不开车，而是坐地铁，你会把他们也包括进 analysis 里吗”，etc.<br/>\n<br/>\n<font size=\"5\">Technical: Data analysis and intuition II</font><br/>\n<br/>\n考察的内容和第二轮是一样的，所以没有做太多准备。真的面试了才发现好像题目风格还是不太一样。<br/>\n第一问：Let’s say you have two features (X1, X2) and one target variable Y, and you want to build an OLS regression model to predict Y. You build a model one Y ~ X1 + X2. Now you also build a model two with transformed feature (X1 - X2) and (X1 + X2). Will you get the same model? What about predictions?<br/>\n回答：Model 肯定不一样，因为 coefficients 不一样。然后我卡壳了。卡了一会儿之后我说，”I know you’ll get the sample model (same predicted value) if you apply a linear transform on features such as aX + b, since the column space of design matrix does not change. But I’m not 100% sure if X1-X2 and X1+X2 is linear transformation.” 我说完这句感觉面试官都无语了  然后她给我写了个矩阵，和我说这个确实是 linear transformation，行吧，我自己纸张了。<br/>\n第二问：如果我们现在用 regularized regression，比如 ridge 或者 lasso，那 coefficients of model one and model two 还一样吗？predicted value 呢？我回答得比较乱，我也不知道正确答案是什么。感觉应该是 coefficients 和 predicted value 都不一样。<br/>\n第三问：公司有一个 daily search log，每一行是一个 query（就是用户搜索什么了）。现在我们取一个 10% 的 random sample. 怎么用这个 sample 估计在 daily log 里一共有多少 unique query?<br/>\n我一开始以为 unique query 是类似于 select distinct，后来 clarify 了，原来定义是“a query showing up exactly once” 所以如果全部的 query 是 (q1, q1, q2, q3)，那number of unique query 是 2 而不是 3.<br/>\n我的回答是，不如先计算 number of unique query in the random sample 然后等比例放大。然后面试官问我这个方法有什么问题，我就说会高估 number of unique query in the population，因为可能某个 query 正好在 sample 里只出现了一次，但是在 population 中却出现了多次。然后问我有没有什么更好的办法？我说我想到两个方法：（1）还是等比例估计，但是 apply some correction afterwards（有点瞎说了）(2) 可以做一个 stats model 比如假设所有的 log 服从一个 multinomial distribution. 最后面试官提示的正解好像是 model number of occurrence of each query，可以用 Poisson 之类的。<br/>\n<br/>\n<font size=\"5\">Technical: Programming</font><br/>\n<br/>\n体验不太好的一轮，因为面试官直接迟到了十分钟，也不表示一下 sorry 或者解释两句。而且面试全程一直在打断我说话，还在椅子上面前后摇来摇去。<br/>\n问题本身不难。第一个问题是，给你一个 binary classification model 的 output csv，有两个 column: actual label, predicted prob. 其中 true positive case 大概占全部的 5%. 先是问“你会用什么 metric 来衡量这个模型的好坏？”，然后自然引入到写一个 Python function 来计算 precision/recall curve. 脑子有点卡壳，一下子没想起来 precision 的定义。Python 函数倒是很好写。<br/>\n第二个问题是，假设现在给你一个 regression model 的 output，这个模型是预测每个国家的 revenue 有多少。CSV 一共有三列：country, actual revenue, predicted revenue. 先是讨论应该用什么 metric. 我说可以考虑 MSE 或者 weighted MSE，然后面试官就各种 challenge：你为什么看 mean 而不是 sum，哪个比较好，etc. 最后说那就 implement RMSE 好了。然后写到一半说 “Wait, why are you taking the difference?” 然后说我们想要的是 percentage: sqrt(avg(sum_i (predicted_i / actual_i - 1)^2)).<br/>\n写完了之后问我怎么得出 percentage RMSE（我都没见过这个 metric）的 CI，答“bootstrap”，然后写到一半又说 “Wait a second, why is your bootstrap sample the same sample size as the original sample?” 然后我就说 “Oh, this is quite common and I think it’s the standard procedure of nonparametric bootstrap?” 然后他说“那你是不是有概率得到一个和原来的 sample 一样的 bootstrap sample 呢？”我还以为是考概率题，正准备算，然后面试官说 “Oh actually it’s not very likely. Never mind.”</td></div>",
  "processedContent": "# 狗家数据科学家面试详尽面经：统计、建模与编程实战\n\n## 基本信息（公司/岗位/结果/难度）\n- **公司**：Meta\n- **岗位**：数据科学家（Data Scientist）\n- **面试结果**：未提及/不明确\n- **难度**：4\n\n## 时间线\n- 面试轮次安排未明确具体日期，推测为近期完成的多轮线上技术面试。\n- 整体流程包含多个技术轮次及编程考察，未提及HR面或后续反馈时间。\n\n## 面试过程\n\n### 第一轮：统计基础（Statistics）\n面试官友好，注重引导。问题围绕置信区间、线性模型估计与假设检验展开。\n\n1. **置信区间宽度问题**\n   - 给定样本量100，样本均值100，误差范围10，置信区间[70,90]。产品经理认为区间太宽，如何改进？\n   - 回答：可通过增加样本量降低标准误，从而缩小CI。\n   - 追问：若样本量增至10000，CI如何变化？是否有其他方法？\n   - 回答：CI显著变窄；也可通过提高显著性水平（如α=0.1而非0.05）来缩窄CI，但会牺牲置信度。\n\n2. **线性模型参数估计**\n   - 模型Y = Xb，n=100数据点，m个特征，如何估计b？\n   - 回答：使用普通最小二乘法（OLS），估计式为 \\((X^T X)^{-1} X^T Y\\)，前提是m < n。\n   - 追问：若m > n（高维小样本），怎么办？\n   - 回答：考虑特征选择、正则化（Lasso/Ridge）、或尝试非线性模型（如随机森林）。提及上采样不合理，已自我反思。\n\n3. **特征相关性检验**\n   - 如何判断某特征是否相关？\n   - 回答：查看回归系数的t检验结果。\n   - 追问：t检验构造方式？原假设与备择假设？\n   - 回答：H₀: βᵢ = 0，H₁: βᵢ ≠ 0。\n   - 再追问：为何是t分布？直觉解释？\n   - 回答：因标准误未知需估计，导致统计量服从t分布而非正态；若σ已知则为z检验。\n\n---\n\n### 第二轮：数据分析与业务直觉 I\n聚焦YouTube Music应用场景，考察实际问题拆解能力。\n\n- **场景问题**：律师担心用户听“通勤”歌单时开车更快，作为DS如何分析？\n- 回答思路：\n  - 初步可用t检验比较听/不听通勤歌单用户的平均车速差异。\n  - 可进一步建模控制混杂变量（如路况、时间段等）。\n- 面试官深入追问细节：\n  - 分析人群定义（是否包括非司机？）\n  - 数据粒度（按session还是trip？）\n  - 处理中途切换歌单的情况\n  - 如何定义“影响”——因果推断挑战\n- 总结：开放式问题，重在逻辑清晰、边界明确、识别潜在偏差。\n\n---\n\n### 第三轮：数据分析与业务直觉 II\n延续前轮风格，但更偏重统计建模理解。\n\n1. **线性变换对OLS模型的影响**\n   - 原始模型：Y ~ X₁ + X₂\n   - 新模型：Y ~ (X₁−X₂) + (X₁+X₂)\n   - 问：两个模型是否相同？预测值是否一致？\n   - 回答：系数不同，但若新特征是原始特征的线性组合，则设计矩阵列空间不变，预测值应相同。面试中未能立即确认此点，后被提示纠正。\n\n2. **正则化下的模型一致性**\n   - 若使用Ridge或Lasso回归，两模型的系数和预测是否还相同？\n   - 回答混乱，不确定正确答案。\n   - 推测：由于正则化项依赖于特征尺度与结构，即使线性变换，惩罚项不同 → 系数与预测均可能不同。\n\n3. **估计总体唯一查询数（Unique Query）**\n   - 定义澄清：“unique query”指在整个日志中仅出现一次的query（frequency=1），非distinct count。\n   - 目标：用10%随机抽样估计全量日志中frequency=1的query数量。\n   - 初始回答：直接放大样本中frequency=1的数量 → 易高估（因某些query在总体中多次出现，但恰在样本中只现一次）。\n   - 改进思路：\n     - 提出校正因子（模糊）\n     - 建议建模每个query出现频次，如假设服从Poisson分布，利用稀有事件建模思想。\n   - 面试官提示方向：可通过建模频次分布进行更准确估计。\n\n---\n\n### 第四轮：编程能力考察（Programming）\n体验较差，面试官迟到且频繁打断，提问方式较压迫。\n\n1. **分类模型评估指标与实现**\n   - 输入：CSV含actual label和predicted prob，正例占比约5%。\n   - 问题1：选用哪些评估指标？\n     - 回答：Precision、Recall、F1、PR曲线、AUC等，尤其关注类别不平衡场景。\n   - 问题2：写函数计算Precision-Recall曲线。\n     - 实现顺利，但初期卡壳precision定义（TP / (TP + FP)）。\n\n2. **回归模型评估与RMSE变体**\n   - 输入：country, actual revenue, predicted revenue\n   - 问题1：选择什么metric？\n     - 回答：MSE、RMSE、Weighted MSE（按国家权重）\n   - 面试官挑战：为何看mean而不是sum？哪个更有意义？\n   - 最终要求：实现一种“百分比RMSE”：\\(\\sqrt{\\text{avg}_i \\left(\\frac{\\text{predicted}_i}{\\text{actual}_i} - 1\\right)^2}\\)\n   - 编码实现无误。\n\n3. **Bootstrap构建CI**\n   - 问：如何为上述百分比RMSE构造置信区间？\n   - 回答：使用非参数bootstrap方法。\n   - 面试官质疑：“为何bootstrap样本大小与原样本相同？”\n   - 回答：这是标准做法，尽管可能复现原样本，但概率极低，不影响整体有效性。\n   - 面试官最终表示接受该做法。\n\n## 题目总结\n\n### 统计理论\n- 如何缩小置信区间？增大样本量 vs 提高α水平\n- OLS估计公式及其前提条件\n- m > n时的回归建模范式（正则化、特征选择）\n- 回归系数t检验的构造与分布原理（为何是t分布）\n\n### 数据分析与业务建模\n- 开放式因果推断问题：音乐播放与驾驶行为的关系\n  - 如何定义目标群体、处理混杂因素、设计分析框架\n- 线性变换对OLS模型预测的影响\n- 正则化模型在特征变换下的一致性（系数与预测）\n- 从抽样数据估计总体中“仅出现一次”的元素数量（frequency=1 estimation）\n\n### 编程与模型评估\n- 不平衡分类任务的评估指标选择\n- 手动实现Precision-Recall曲线\n- 回归任务中的加权误差与新型RMSE（基于相对误差）\n- 使用Bootstrap为复合metric构建置信区间\n\n## 个人总结（经验与建议）\n- Meta的DS面试强调扎实的统计基础，尤其是经典推断方法的理解（如t检验、CI、OLS）。\n- 业务问题开放性强，重点不在“标准答案”，而在逻辑链条完整、假设明确、能应对深度追问。\n- 编程题不难，但要求清晰表达思路，并能灵活应对面试官的临时调整与质疑。\n- 建议平时多练习：\n  - 统计直觉题（如“为什么是t分布”这类问题）\n  - 抽样与估计类问题（特别是稀有事件建模）\n  - Bootstrap的实际应用与常见误区\n- 注意沟通节奏，遇到打断保持冷静，确保理解问题本质再作答。",
  "company": "Meta",
  "role": "数据科学家",
  "difficulty": 4,
  "tags": [
    "数据科学家",
    "统计建模",
    "业务分析",
    "编程题",
    "Bootstrap",
    "线性回归",
    "假设检验",
    "Meta"
  ],
  "comments": [],
  "usefulVotes": 0,
  "uselessVotes": 0,
  "shareCount": 0,
  "isAnonymous": true
}