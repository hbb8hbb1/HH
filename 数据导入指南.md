# 多公司-岗位数据导入指南

## 📋 数据格式要求

你的数据需要是 **JSON 格式**，每个文件包含一个帖子的信息。JSON 文件需要包含以下字段：

### 必需字段
```json
{
  "title": "帖子标题（如：Meta 2025应届软件工程师伦敦岗位面试经验）",
  "company": "公司名称（如：Meta、Amazon、Microsoft）",
  "role": "岗位名称（如：Software Engineer、Data Scientist）",
  "originalContent": "原始内容（HTML 或纯文本）",
  "processedContent": "处理后的内容（Markdown 格式，可选）"
}
```

### 可选字段
```json
{
  "difficulty": 4,  // 难度评分 1-5
  "tags": ["Meta", "软件工程师", "应届生招聘", "海外岗位", "London"],
  "sourceUrl": "原始链接（如果有）"
}
```

## 📁 数据组织方式

建议按公司-岗位组织数据：

```
新数据/
├── amazon_data_science/
│   ├── post_001.json
│   ├── post_002.json
│   └── ...
├── microsoft_software_engineer/
│   ├── post_001.json
│   ├── post_002.json
│   └── ...
└── 其他公司-岗位/
    └── ...
```

## 🚀 导入步骤

### 方法 1：使用现有的导入脚本（推荐）

如果你已经有 JSON 格式的数据：

1. **准备数据目录**
   ```bash
   # 将所有 JSON 文件放在一个目录下
   mkdir -p ~/Desktop/代码/新数据
   # 将你的 JSON 文件复制到这个目录
   ```

2. **确保后端服务器运行**
   ```bash
   cd ~/Desktop/代码/HH-main/server
   PORT=5001 node index.js
   ```

3. **运行导入脚本**
   ```bash
   cd ~/Desktop/代码/hh_pipeline
   python3 import_posts_via_api.py \
     --api-base http://127.0.0.1:5001 \
     --data-dir ~/Desktop/代码/新数据 \
     --email "your@email.com" \
     --password "yourpassword" \
     --name "Importer"
   ```

### 方法 2：如果数据是 HTML 格式

如果你有 HTML 格式的数据，需要先转换为 JSON：

1. **将 HTML 文件放在 `html/` 目录**
2. **运行 HTML 解析脚本**
   ```bash
   cd ~/Desktop/代码/hh_pipeline
   python3 parse_html_batch.py \
     --html-dir ./html \
     --out-dir ./data_raw \
     --bad-dir ./bad_html
   ```
3. **使用 Gemini 处理（可选，生成 processedContent）**
   ```bash
   export API_KEY="你的 Gemini API Key"
   node process_raw_to_final.mjs ./data_raw ./data_final
   ```
4. **导入到后端**
   ```bash
   python3 import_posts_via_api.py \
     --api-base http://127.0.0.1:5001 \
     --data-dir ./data_final \
     --email "your@email.com" \
     --password "yourpassword"
   ```

### 方法 3：如果数据是文本或其他格式

如果你有文本格式的数据，我可以帮你创建一个转换脚本。请告诉我：
- 数据格式（文本、CSV、Excel 等）
- 数据字段（标题、公司、岗位、内容等）
- 数据示例

## 📝 JSON 文件示例

### 示例 1：亚马逊 Data Science
```json
{
  "title": "Amazon Data Science 2025 面试经验",
  "company": "Amazon",
  "role": "Data Scientist",
  "originalContent": "<div>原始 HTML 内容...</div>",
  "processedContent": "## 基本信息\n- **公司**：Amazon\n- **岗位**：Data Scientist\n\n## 面试过程\n...",
  "difficulty": 4,
  "tags": ["Amazon", "Data Science", "面试经验"]
}
```

### 示例 2：微软软件工程师
```json
{
  "title": "Microsoft Software Engineer 面试经验",
  "company": "Microsoft",
  "role": "Software Engineer",
  "originalContent": "<div>原始 HTML 内容...</div>",
  "processedContent": "## 基本信息\n- **公司**：Microsoft\n- **岗位**：Software Engineer\n\n## 面试过程\n...",
  "difficulty": 3,
  "tags": ["Microsoft", "Software Engineer", "面试经验"]
}
```

## 🔍 验证导入结果

导入完成后，可以：

1. **检查数据库中的帖子数量**
   ```bash
   curl http://localhost:5001/api/posts?page=1&limit=5
   ```

2. **在前端页面查看**
   - 打开 http://localhost:3000
   - 使用搜索功能搜索公司名称（如 "Amazon"、"Microsoft"）
   - 使用筛选功能按公司、岗位筛选

## ⚠️ 注意事项

1. **去重机制**：脚本会自动去重，基于 `title + company + role` 或 `sourceUrl`
2. **批量导入**：如果数据量很大（几百个文件），导入可能需要一些时间
3. **错误处理**：导入失败的记录会显示错误信息，可以单独处理
4. **数据格式**：确保 JSON 文件格式正确，否则会被跳过

## 🆘 需要帮助？

如果你：
- 数据格式不是 JSON：告诉我你的数据格式，我可以帮你创建转换脚本
- 需要批量处理：告诉我数据量，我可以优化导入脚本
- 遇到错误：把错误信息发给我，我帮你解决

## 📤 如何发送数据给我

你可以：
1. **直接粘贴 JSON 示例**：给我几个示例文件，我帮你检查格式
2. **描述数据格式**：告诉我你的数据是什么格式（HTML、文本、CSV 等）
3. **分批发送**：如果数据量大，可以分批发送，我帮你逐个导入

